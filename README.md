# Face Liveness Detection Pipeline - SOTA 2025 Architecture

Pipeline phÃ¡t hiá»‡n giáº£ máº¡o khuÃ´n máº·t (Face Liveness Detection) sá»­ dá»¥ng kiáº¿n trÃºc State-of-the-Art nÄƒm 2025 vá»›i chiáº¿n lÆ°á»£c **Multi-stage Ensemble** vÃ  **Quality Aware**.

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- âœ… **Quality Gate**: Lá»c áº£nh má», gÃ³c quay khÃ´ng há»£p lá»‡
- âœ… **SCRFD Detection**: PhÃ¡t hiá»‡n vÃ  cÄƒn chá»‰nh khuÃ´n máº·t chÃ­nh xÃ¡c
- âœ… **Multi-stage Liveness Ensemble**: 3 nhÃ¡nh káº¿t há»£p
  - **Global Branch**: MiniFASNetV2 - PhÃ¢n tÃ­ch toÃ n cá»¥c
  - **Local Branch**: DeepPixBiS - PhÃ¢n tÃ­ch pixel-wise
  - **Temporal Branch**: Blink detection - PhÃ¡t hiá»‡n chá»›p máº¯t
- âœ… **Face Recognition** (Optional): ArcFace cho 1-1 matching

## ğŸ“‹ YÃªu cáº§u

- Python >= 3.8
- CUDA (optional, cho GPU acceleration)

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
cd /home/maidang/projects/fld-cake-assignment
```

### 2. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 3. Táº£i models hoáº·c Train tá»« dataset cá»§a báº¡n

#### Option A: Train tá»« dataset cá»§a báº¡n (Khuyáº¿n nghá»‹)

Báº¡n cÃ³ dataset trong `data/` vá»›i cáº¥u trÃºc:
```
data/
â”œâ”€â”€ train/normal/  (Real faces)
â”œâ”€â”€ train/spoof/   (Fake faces)
â”œâ”€â”€ test/normal/
â”œâ”€â”€ test/spoof/
â””â”€â”€ dev/normal/
    â””â”€â”€ dev/spoof/
```

**Quick Start Training:**
```bash
# Cháº¡y toÃ n bá»™ pipeline training
./quick_start_training.sh

# Hoáº·c train tá»«ng model
python src/train_global.py --data-dir data --epochs 50
python src/train_local.py --data-dir data --epochs 50
```

Xem chi tiáº¿t trong [TRAINING.md](TRAINING.md)

#### Option B: Sá»­ dá»¥ng pre-trained models

Pipeline cáº§n cÃ¡c model sau (sáº½ tá»± Ä‘á»™ng táº£i khi cháº¡y láº§n Ä‘áº§u vá»›i InsightFace):

- **SCRFD**: Tá»± Ä‘á»™ng táº£i tá»« InsightFace model zoo
- **MiniFASNetV2**: Cáº§n táº£i vÃ  convert sang ONNX
- **DeepPixBiS**: Cáº§n táº£i vÃ  convert sang ONNX
- **ArcFace** (optional): Tá»± Ä‘á»™ng táº£i tá»« InsightFace model zoo

**LÆ°u Ã½**: CÃ¡c model ONNX cáº§n Ä‘Æ°á»£c Ä‘áº·t trong thÆ° má»¥c `models/`:
- `models/minifasnet_v2.onnx`
- `models/deeppixbis.onnx`

Náº¿u khÃ´ng cÃ³ model files, pipeline sáº½ sá»­ dá»¥ng dummy predictions Ä‘á»ƒ test.

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
fld-cake-assignment/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # Cáº¥u hÃ¬nh pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ quality_gate.py      # Quality Gate module
â”‚   â”‚   â”œâ”€â”€ detection.py         # SCRFD Detection & Alignment
â”‚   â”‚   â”œâ”€â”€ liveness_ensemble.py # Multi-stage Ensemble
â”‚   â”‚   â”œâ”€â”€ recognition.py       # ArcFace Recognition (optional)
â”‚   â”‚   â””â”€â”€ pipeline.py          # Pipeline chÃ­nh
â”‚   â””â”€â”€ main.py                  # Entry point
â”œâ”€â”€ models/                      # ThÆ° má»¥c chá»©a model weights
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Cáº¥u hÃ¬nh

Chá»‰nh sá»­a `config/config.yaml` Ä‘á»ƒ tÃ¹y chá»‰nh:

```yaml
pipeline:
  quality_gate:
    max_yaw: 20.0        # GÃ³c quay tá»‘i Ä‘a (degrees)
    blur_threshold: 100.0 # NgÆ°á»¡ng blur detection
    
  liveness:
    global_branch:
      threshold: 0.9      # NgÆ°á»¡ng cho Global branch
      weight: 0.4
    local_branch:
      threshold: 0.8      # NgÆ°á»¡ng cho Local branch
      weight: 0.4
    temporal_branch:
      enabled: true       # Báº­t/táº¯t temporal analysis
      min_blinks: 1      # Sá»‘ láº§n chá»›p máº¯t tá»‘i thiá»ƒu
```

## ğŸ® Sá»­ dá»¥ng

### Xá»­ lÃ½ tá»« camera

```bash
python src/main.py --camera
```

### Xá»­ lÃ½ tá»« video file

```bash
python src/main.py --input video.mp4
```

### Xá»­ lÃ½ vá»›i options

```bash
# Hiá»ƒn thá»‹ chi tiáº¿t scores
python src/main.py --input video.mp4 --show-details

# Giá»›i háº¡n sá»‘ frames
python src/main.py --input video.mp4 --max-frames 100

# LÆ°u output video
python src/main.py --input video.mp4 --output output.mp4

# KhÃ´ng hiá»ƒn thá»‹ window (headless mode)
python src/main.py --input video.mp4 --no-display
```

### Sá»­ dá»¥ng config tÃ¹y chá»‰nh

```bash
python src/main.py --input video.mp4 --config config/custom_config.yaml
```

## ğŸ“Š Káº¿t quáº£

Pipeline tráº£ vá»:

- **Status**: `accepted` (real) hoáº·c `rejected` (fake)
- **Confidence score**: Äiá»ƒm tin cáº­y (0-1)
- **Detailed scores**: Global, Local, Temporal scores
- **Statistics**: Thá»‘ng kÃª xá»­ lÃ½

### VÃ­ dá»¥ output:

```
=== Káº¾T QUáº¢ CUá»I CÃ™NG ===
Status: accepted
Message: Face is REAL
Confidence: 0.892
Pass Rate: 85.00%

=== THá»NG KÃŠ ===
Total frames: 100
Quality passed: 95 (95.00%)
Detection passed: 90 (90.00%)
Liveness passed: 85 (85.00%)
Final accepted: 85 (85.00%)
```

## ğŸ”§ Kiáº¿n trÃºc Pipeline

```
Input Video Stream
    â†“
Quality Gate (Blur/Pose Check)
    â†“
SCRFD Detection & Alignment
    â†“
Liveness Ensemble
    â”œâ”€â”€ Global Branch (MiniFASNetV2)
    â”œâ”€â”€ Local Branch (DeepPixBiS)
    â””â”€â”€ Temporal Branch (Blink Detection)
    â†“
Fusion & Decision
    â†“
Real/Fake Result
```

## ğŸ›¡ï¸ Chá»‘ng táº¥n cÃ´ng

Pipeline cÃ³ kháº£ nÄƒng chá»‘ng:

- âœ… **Print Attack**: Nhá» Local Branch (DeepPixBiS) phÃ¢n tÃ­ch pixel
- âœ… **Replay Attack**: Nhá» Global Branch (MiniFASNet) phÃ¡t hiá»‡n MoirÃ© pattern
- âœ… **3D Mask Attack**: Nhá» Quality Gate vÃ  Ä‘á»™ sÃ¢u áº£nh
- âœ… **Static Image**: Nhá» Temporal Branch yÃªu cáº§u chá»›p máº¯t

## ğŸ“ LÆ°u Ã½

1. **Models**: Cáº§n táº£i vÃ  convert cÃ¡c model ONNX (MiniFASNetV2, DeepPixBiS) vÃ o thÆ° má»¥c `models/`
2. **GPU**: Äá»ƒ tÄƒng tá»‘c, cÃ i `onnxruntime-gpu` vÃ  cÃ³ CUDA
3. **Temporal Branch**: Cáº§n xá»­ lÃ½ nhiá»u frames liÃªn tiáº¿p Ä‘á»ƒ phÃ¡t hiá»‡n chá»›p máº¯t
4. **InsightFace**: SCRFD vÃ  ArcFace sáº½ tá»± Ä‘á»™ng táº£i model khi cháº¡y láº§n Ä‘áº§u

## ğŸ› Troubleshooting

### Lá»—i: "InsightFace not available"
```bash
pip install insightface
```

### Lá»—i: "ONNX Runtime not available"
```bash
pip install onnxruntime
# Hoáº·c vá»›i GPU:
pip install onnxruntime-gpu
```

### Lá»—i: "Model not found"
- Äáº£m báº£o model files Ä‘Æ°á»£c Ä‘áº·t Ä‘Ãºng trong `models/`
- Hoáº·c pipeline sáº½ dÃ¹ng dummy predictions Ä‘á»ƒ test

### Lá»—i: "Cannot open camera"
- Kiá»ƒm tra camera index: `--camera-id 1` (thá»­ cÃ¡c index khÃ¡c)
- Kiá»ƒm tra quyá»n truy cáº­p camera

## ğŸ“ Training vá»›i Dataset cá»§a báº¡n

Báº¡n cÃ³ thá»ƒ train models tá»« dataset cá»§a riÃªng báº¡n! Xem hÆ°á»›ng dáº«n chi tiáº¿t:

- **[TRAINING.md](TRAINING.md)**: HÆ°á»›ng dáº«n training Ä‘áº§y Ä‘á»§
- **Quick Start**: `./quick_start_training.sh`

### Dataset Format

Dataset cáº§n cÃ³ cáº¥u trÃºc:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ normal/  (Real faces - .jpg hoáº·c .png)
â”‚   â””â”€â”€ spoof/   (Fake faces - .jpg hoáº·c .png)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ normal/
â”‚   â””â”€â”€ spoof/
â””â”€â”€ dev/
    â”œâ”€â”€ normal/
    â””â”€â”€ spoof/
```

### Training Commands

```bash
# PhÃ¢n tÃ­ch dataset
python src/analyze_data.py --data-dir data --visualize

# Train Global Branch
python src/train_global.py --data-dir data --epochs 50

# Train Local Branch
python src/train_local.py --data-dir data --epochs 50

# Evaluate models
python src/evaluate.py --model-type global --checkpoint checkpoints/best_global.pth

# Convert to ONNX
python src/convert_to_onnx.py --model-type global \
    --checkpoint checkpoints/best_global.pth \
    --output models/minifasnet_v2.onnx
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [InsightFace](https://github.com/deepinsight/insightface)
- [SCRFD Paper](https://arxiv.org/abs/2105.04714)
- [ArcFace Paper](https://arxiv.org/abs/1801.07698)
- [MediaPipe Face Mesh](https://google.github.io/mediapipe/solutions/face_mesh.html)

## ğŸ“„ License

MIT License

## ğŸ‘¥ Contributors

Developed for eKYC applications with SOTA 2025 architecture.


